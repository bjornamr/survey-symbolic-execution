% !TEX root = main.tex

\section{Constraint solving}
\label{se:constraint-solving}

Constraint satisfaction problems arise in many domains, including analysis, testing, and verification of software programs. Constraint solvers are decision procedures for problems expressed in logical formulas: for instance, the boolean satisfiability problem (also known as SAT) aims at determining whether there exists an interpretation of the symbols of a formula that makes it true. Although SAT is a well-known NP-complete problem, recent advances have moved the boundaries for what is intractable when it comes to practical applications~\cite{SMT-CACM11}. 

% linear arithmetic inequalities
Observe that some problems are more naturally described with languages that are more expressive than the one of boolean formulas with logical connectives. For this reason, satisfiability modulo theories (SMT) generalize the SAT problem with supporting theories to capture formulas involving, for instance, linear arithmetic and operations over \iffullver{arrays (see, e.g., Section~\ref{ss:fully-symbolic-memory}).}{arrays.} SMT solvers map the atoms in an SMT formula to fresh boolean variables: a SAT decision procedure checks the rewritten formula for satisfiability, and a theory solver checks the model generated by the SAT procedure.

%\mytempedit{In particular, SMT-compliant theory solvers are required to be able to: (i) work incrementally when checking for consistency as novel constraints are added, (ii) support backtracking, i.e., constraint removal, and (iii) provide explanations for inconsistent constraints~\cite{Abraham15}.}

SMT solvers show several distinctive strengths. Their core algorithms are generic, and can handle complex combinations of many individual constraints. They can work incrementally and backtrack as constraints are added or removed, and provide explanations for inconsistencies. Theories can be added and combined in arbitrary ways, e.g., to reason about arrays of strings. Decision procedures do not need to be carried out in isolation: often, they are profitably combined to reduce the amount of time spent in heavier procedures, e.g., by solving linear parts first in a non-linear arithmetic formula. Incomplete procedures are valuable too: complete but expensive procedures get called only when conclusive answers could not be produced. All these factors allows SMT solvers to tackle large problems that no single procedure can solve in isolation\footnote{We refer the interested reader to~\cite{BKM14} for an exhaustive introduction to SMT solving, and to~\cite{SC2} for a discussion of its distinctive strengths.}.
% SHORTER VERSION
% }%\footnote{\cite{BKM14,SC2} provide interesting discussions of the strengths of SMT solvers.}.}


%\mytempedit{SMT solvers show a number of distinctive strengths. They can work incrementally as constraints are added to formulas, backtrack for constraint removal, and provide explanations for inconsistent constraints. Their core algorithms are generic and can handle complex combinations of many individual constraints. Theories can be added and, more importantly, combined in arbitrary ways, e.g., to reason about arrays of strings. Decision procedures are not required to be carried out in isolation: often, they can profitably be combined to reduce the amount of time spent in heavier procedures, e.g., by solving linear problem parts first for a non-linear arithmetic formula. Incomplete procedures are valuable too: complete but expensive procedures get called only when conclusive answers could not be produced. The combination of these factors allows SMT solvers to tackle large problems that no single procedure can solve in isolation\footnote{We refer the interested reader to~\cite{BKM14} for an exhaustive introduction to SMT solving, and to~\cite{SC2} for a discussion of its distinctive strengths.}.}

% STP~\cite{STP-CAV07,STP-TR07} solver
% {\sc MineSweeper}~\cite{MineSweeper-BOTNET08}, and {\sc AEG}~\cite{AEG-NDSS11}
In a symbolic executor, constraint solving plays a crucial role in checking the feasibility of a path, generating assignments to symbolic variables, and verifying assertions.
%
Over the years, different solvers have been employed by symbolic executors, depending on the supported theories and the relative performance at the time. For instance, the STP~\cite{STP-CAV07} solver has been employed in, e.g., {\sc EXE}~\cite{EXE-CCS06}, {\sc KLEE}~\cite{KLEE-OSDI08}, and {\sc AEG}~\cite{AEG-NDSS11}, which all leverage its support for bit-vector and array theories. Other executors such as {\sc Java PathFinder}~\cite{PATHFINDER-ASE10} have complemented SMT solving with additional decision procedures, e.g., libraries for constraint programming~\cite{CHOCO} and heuristics to handle complex non-linear mathematical constraints~\cite{CORAL-NFM11}.

Recently, Z3~\cite{Z3-TACS08} has emerged as leading solution for SMT solving. Developed at Microsoft Research, Z3 offers cutting-edge performance and supports a large number of theories, including bit-vectors, arrays, quantifiers, uninterpreted functions, linear integer and real arithmetic, and non-linear arithmetic. 
%
%Effective support for strings has been recently offered by Z3-str~\cite{ZZG-FSE13}, an extension of Z3 that makes it possible to treat string as a primitive type, allowing the solver to reason on common string operations such as concatenation, substring, and replacement.
Its Z3-str~\cite{ZZG-FSE13} extension makes it possible to treat also strings as a primitive type, allowing the solver to reason on common string operations such as concatenation, substring, and replacement.
%
Z3 is employed in most recently appeared symbolic executors such as {\sc Mayhem}~\cite{MAYHEM-SP12}, {\sc SAGE}~\cite{SAGE-QUEUE12}, and {\sc Angr}~\cite{ANGR-SSP16}. Due to the extensive number of supported theories in Z3, such executors typically do not to employ additional decision procedures.

%The two most popular solvers used in symbolic executors are STP and Z3. STP~\cite{STP-CAV07,STP-TR07} is an SMT solver with bitvector and array theories initially developed at Stanford and employed in, e.g., {\sc EXE}~\cite{EXE-CCS06}, {\sc KLEE}~\cite{KLEE-OSDI08}, {\sc MineSweeper}~\cite{MineSweeper-BOTNET08}, and {\sc AEG}~\cite{AEG-NDSS11}. Z3~\cite{Z3-TACS08} is an SMT solver developed at Microsoft with support for nonlinear arithmetic, bitvector, and array theories, and is used in, e.g., {\sc Mayhem}~\cite{MAYHEM-SP12}, {\sc SAGE}~\cite{SAGE-QUEUE12}, and {\sc Angr}~\cite{ANGR-SSP16}. CVC3~\cite{CVC3-CAV07} is another SMT solver that supports theories for linear arithmetic, bitvectors, arrays, and quantifiers, and is employed in {\sc Java PathFinder}~\cite{PATHFINDER-ASE10} along with CHOCO~\cite{CHOCO} for integer/real constraints and CORAL~\cite{CORAL-NFM11} for complex mathematical constraints. Modern symbolic executors can typically choose between different underlying solvers through a common API, and also resort to a native interface to a specific solver for better performance.

%only for efficiency reasons.

%For instance, many solvers have the development of ~\cite{PATHFINDER-ASE10} can use a large number of SMT solvers, including Yices, 
%~\cite{YICES-CAV06} is an incremental solver with support for rational and integer linear arithmetic, bitvectors, and arrays, and was originally used in 
%In Table~\ref{tab:solvers} we report a number of constraint solving tools used in popular symbolic execution engines.

\iffalse
\begin{figure}[ht]
  \centering
  \begin{adjustbox}{width=1\columnwidth}
  \begin{small}
  \begin{tabular}{| l | p{8cm} | p{4cm} |}
    \hline      
    Constraint solver & Description & Used in  \\ \hline\hline
    \cite{STP-TR07} & SMT + bitvectors, arrays & ~\cite{EXE-CCS06,KLEE-OSDI08,MineSweeper-BOTNET08,AEG-NDSS11}, SPF? \\
    \cite{Z3-TACS08} & SMT + (non)linear arithmetic, bitvectors, arrays & ~\cite{FIRMALICE-NDSS15,MAYHEM-SP12}, SAGE \\
    \cite{CVC3-CAV07} & SMT + linear arithmetic, bitvectors, arrays, quantifiers & SPF \\
    \cite{YICES-CAV06} & SMT + rational and integer linear arithmetic, bitvectors, arrays & originally in SPF\\
    \hline  
  \end{tabular}
  \end{small}
  \end{adjustbox}
  \caption{List of constraint solvers.}
  \label{tab:solvers}
\end{figure}
\fi

% feasibility or applicability? TODO
However, despite the significant advances observed over the past few years -- which also made symbolic execution practical in the first place~\cite{CS-CACM13} -- constraint solving remains one of the main obstacles to the scalability of symbolic execution engines, and also hinders its feasibility in the face of constraints that involve expensive theories (e.g., non-linear arithmetic) or opaque library calls.

%\subsection{Optimization Techniques}
%\label{ss:constraint-opt}

% handling or skipping over
In the remainder of this section, we address different techniques to extend the range of programs \iffullver{that can be handled by}{amenable to} symbolic execution and to optimize the performance of constraint solving. Prominent approaches consist in: (i) reducing the size and complexity of the constraints to check, (ii) unburdening the solver by, e.g., resorting to constraint solution caching, deferring of \iffullver{constraint solver queries}{solver queries}, or concretization, and (iii) augmenting symbolic execution to handle constraints problematic for decision procedures.

%We conclude by pointing out potential directions to improve support for non-linear arithmetic}.

%\mytempedit{and (iii) augmenting symbolic execution with techniques aimed at handling constraints that are problematic for the underlying decision procedure. We conclude the section by pointing out potential research directions to improve support for non-linear arithmetic}.

%: (i) {\em constraint reduction} techniques aim at simplifying constraints fed to a solver by rewriting them into a shorter form: (ii) techniques for {\em reuse of constraint solutions} explore the space-time trade-off of retrieving previously computed query results rather than repeating expensive satisfiability checks.

\myparagraph{Constraint Reduction} 
A common optimization approach followed by both solvers and symbolic executors is to reduce constraints into simpler forms. For example, the {\em expression rewriting} optimization can apply classical techniques from optimizing compilers such as constant folding, strength reduction, and simplification of linear expressions (see, e.g., {\sc KLEE}~\cite{KLEE-OSDI08}).

{\sc EXE}~\cite{EXE-CCS06} introduces a {\em constraint independence} optimization that exploits the fact that a set of constraints can frequently be divided into multiple independent subsets of constraints. This optimization interacts well with query result caching strategies, and offers an additional advantage when an engine asks the solver about the satisfiability of a specific constraint, as it removes irrelevant constraints from the query. In fact, independent branches, which tend to be frequent in real programs, could lead to unnecessary constraints that would get quickly accumulated.

Another fact that can be exploited by reduction techniques is that the natural structure of programs can lead to the introduction of more specific constraints for some variables as the execution proceeds. Since path conditions are generated by conjoining new terms to an existing sequence, it might become possible to rewrite and optimize existing constraints. For instance, adding an equality constraint of the form $x:=5$ enables not only the simplification to true of other constraints over the value of the variable (e.g., $x>0$), but also the substitution of the symbol $x$ with the associated concrete value in the other subsequent constraints involving it. The latter optimization is also known as {\em implied value concretization} and, for instance, it is employed by {\sc KLEE}~\cite{KLEE-OSDI08}.

In a similar spirit, {\sc \stwoe}~\cite{CKC-TOCS12} introduces a bitfield-theory expression simplifier to replace with concrete values parts of a symbolic variable that bit operations mask away. For instance, for any 8-bit symbolic value $v$, the most significant bit in the value of expression $v\,|\,10000000_2$ is always 1. The simplifier can propagate information across the tree representation of an expression, and if each bit in its value can be determined, the expression is replaced with the corresponding constant.
 
%path conditions in a symbolic executor are typically generated by conjoining a new term to an existing (and possibly satisfiable) sequence of constraints. As the exploration proceeds, the natural structure of programs means that constraints might become more specific for some variables, and constraints can be rewritten accordingly. 

%\subsubsection{Reuse of Constraint Solutions}
%\label{ss:constraint-reuse}

%\subsection{Unburdening the Constraint Solver} 
%\label{ss:solver-unburdening}

\myparagraph{Reuse of Constraint Solutions} 
The idea of reusing previously computed results to speed up constraint solving can be particularly effective in the setting of a symbolic executor, especially when combined with other techniques such as constraint independence optimization. Most reuse approaches for constraint solving are currently based on semantic or syntactic equivalence of the constraints.

{\sc EXE}~\cite{EXE-CCS06} caches the results of constraint solutions and satisfiability queries in order to reduce as much as possible the need for calling the solver. A cache is handled by a server process that can receive queries from multiple parallel instances of the execution engine, each exploring a different program state.

{\sc KLEE}~\cite{KLEE-OSDI08} implements an incremental optimization strategy called {\em counterexample caching}. Using a cache, constraint sets are mapped to concrete variable assignments, or to a special null value when a constraint set is unsatisfiable. When an unsatisfiable set in the cache is a subset for a given constraint set $S$, $S$ is deemed unsatisfiable as well. Conversely, when the cache contains a solution for a superset of $S$, the solution trivially satisfies $S$ too. Finally, when the cache contains a solution for one or more subsets of $S$, the algorithm tries substituting in all the solutions to check whether a satisfying solution for $S$ can be found.

{\em Memoized symbolic execution}~\cite{MEMO-ISSTA12} is motivated by the observation that symbolic execution often results in re-running largely similar sub-problems, e.g., finding a bug, fixing it, and then testing the program again to check if the fix was effective. The taken choices during path exploration are compactly encoded in a prefix tree, opening up the possibility to reuse previously computed results in successive runs.
%  in a trie-based data structure

The Green framework~\cite{GREEN-FSE12} explores constraint solution reuse across runs of not only the same program, but also similar programs, different programs, and different analyses. Constraints are distilled into their essential parts through a {\em slicing} transformation and represented in a canonical form to achieve good reuse, even within a single analysis run. \cite{JGY-ISSTA15} presents an extension to the framework that exploits logical implication relations between constraints to support constraint reuse and faster execution times.

%\subsection{Other Optimizations in Symbolic Executors}
%\subsection{Reducing the Symbolic Executor's Pressure on Constraint Solvers}
%\label{ss:reducing-constraint-solver-pressure}

%In this section we present a number of other optimizations that become possible in the setting of a symbolic executor to reduce the time spent in the constraint solver.

\myparagraph{Lazy Constraints}
\cite{UCKLEE-USEC15} adopts a timeout approach for constraint solver queries. In their initial experiments, the authors traced most timeouts to symbolic division and remainder operations, with the worst cases occurring when an unsigned remainder operation had a symbolic value in the denominator.
They thus implemented a solution that works as follow: when the executor encounters a branch statement involving an expensive symbolic operation, it will take both the true and false branches and add a {\em lazy} constraint on the result of the expensive operation to the path conditions. When the exploration reaches a state that satisfies some goal (e.g., an error is found), the algorithm will check for the feasibility of the path, and suppress it if deemed as unreachable in a real execution.

Compared to the {\em eager} approach of checking the feasibility of a branch as encountered (Section~\ref{ss:unrealizable-paths}), a lazy strategy may lead to a larger number of active states, and in turn to more solver queries. However, the authors report that the delayed queries are in many cases more efficient than their eager counterparts: the path constraints added after a lazy constraint can in fact narrow down the solution space for the solver.

\begin{figure}[t]
  \begin{center}
  \begin{subfigure}{.43\textwidth}
    \vspace{0mm}
    \begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
    1. void test(int x, int y) {
    2.    if (non_linear(y) == x) 
    3.      if (x > y + 10) ERROR; }
    \end{lstlisting}
    %\vspace{8.5mm}
    %\caption{}
  \end{subfigure}%
    \begin{subfigure}{.43\textwidth}
    %\vspace{-5.2mm}
    \begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
      4. int non_linear(int v) {
      5.    return (v*v) % 50;
      6. }
    \end{lstlisting}
    %\vspace{3.5mm}
    %\caption{}
  \end{subfigure}%
  \end{center}
  \vspace{-4.0mm}
  \caption{Example with non-linear constraints.}
  \label{fi:non-linear-constraints}
  \vspace{-2mm}
\end{figure}


\myparagraph{Concretization}
\cite{CS-CACM13} discusses limitations of classical symbolic execution in the presence of formulas that constraint solvers cannot solve, at least not efficiently. A concolic executor generates some random input for the program and executes it both concretely and symbolically: a possible value from the concrete execution can be used for a symbolic operand involved in a formula that is inherently hard for the solver, albeit at the cost of possibly sacrificing soundness in the exploration. 
%For instance, in the presence of three nested branches with only one being non-linear, {\sc DART}~\cite{DART-PLDI05} starts from a random valid input for the function, and then alters it when symbolically exploring the two linear branches. The work resorts to concretization also to avoid performing expensive or imprecise alias analysis on pointers. % with only one of them being


\boxedexample{In the code fragment of Figure~\ref{fi:non-linear-constraints}, the engine stores a non-linear constraint of the form $\alpha_x = (\alpha_y*\alpha_y)\,\%\,50$ for the $true$ branch at line 2. A solver that does not support non-linear arithmetic fails to generate any input for the program. However, a concolic engine can exploit concrete values to help the solver. For instance, if $x=3$ and $y=5$ are randomly chosen as initial input parameters, then the concrete execution does not take any of the two branches. Nonetheless, the engine can reuse the concrete value of $y$, simplifying the previous query as $\alpha_x = 25$ due to $\alpha_y = 5$. The straightforward solution to this query can now be used by the engine to explore both branches. Notice that if the value of $y$ is fixed to $5$, then there is no way of generating a new input that takes the first but not the second branch, inducing a false negative. In this case, a trivial solution could be to rerun the program choosing a different value for $y$ (e.g., if $y=2$ then $x=4$, which satisfies the first but not the second branch).   
}


% suggests to
To partially overcome the incompleteness due to concretization,~\cite{PRV-ISSTA11} suggests {\em mixed concrete-symbolic solving}, which considers {\em all} the path constraints collectable over a path before binding one or more symbols to specific concrete values. Indeed, {\sc DART}~\cite{DART-PLDI05} concretizes symbols based on the path constraints collected up to a target branch. In this manner, a constraint contained in a subsequent branch in the same path is not considered and it may be not satisfiable due to already concretized symbols. If this happen, {\sc DART} restarts the execution with different random concrete values, hoping to be able to satisfy the subsequent branch. The approach presented in~\cite{PRV-ISSTA11} requires instead to detect {\em solvable} constraints along a full path and to delay concretization as much as possible.

\myparagraph{Handling Problematic Constraints}
Strong SMT solvers allow executors to handle more path constraints directly, reducing the need to resort to concretization. This also results in a lower risk to incur a {\em blind commitment} to concrete values~\cite{DA-FSE14}, which happens when the under-approximation of path conditions from a random choice of concrete values for some variables results in an arbitrary restriction of the search space.
\revedit{However, the decision problem for certain classes of constraints is well known to be undecidable, e.g., like non-linear integer arithmetic, or the theory of reals with trigonometric functions often used to model real-world systems.}
%\revedit{However, problems such as non-linear integer arithmetic or the theory of reals together with trigonometric functions are well known to be undecidable.} % SHORT VERSION
%Unfortunately, some constraints remain prohibitive for SMT solvers: for instance, non-linear integer arithmetic is undecidable in general; also, a branch condition might contain calls to opaque library methods such as trigonometric functions that would require special extensions to the solver to reason about.

\cite{DA-FSE14} proposes a {\em concolic walk} algorithm that can tackle control-flow dependencies involving non-linear arithmetic and library calls. The algorithm treats assignments of values to variables as a valuation space: the solutions of the linear constraints define a polytope that can be walked heuristically, while the remaining constraints are assigned with a fitness function measuring how close a valuation point is to matching the constraint. An adaptive search is performed on the polytope as points are picked on it and non-linear constraints evaluated on them. Compared to mixed concrete-symbolic solving~\cite{PRV-ISSTA11}, both techniques seek to avoid blind commitment. However, concolic walk does not rely on the solver for obtaining all the concrete inputs needed to evaluate complex constraints, and implements search heuristics that guide the walk on the polytope towards promising regions.

% Symcretic execution
% , which determines how close the branch conditions are to being satisfied and alters the concrete inputs to move closer to a full solution
%For instance, if an {\tt assert} statement is guarded by a branch condition that can be proven unsatisfiable, then there is no need to take into account all the other constraints along the path to the entry point to declare the target unreachable. A traditional concolic executor reasons instead about all the constraints along a path with a top-down approach, making it hard to detect the unreachability of a target statement because of constraints ``deep'' in the path.

\cite{DA-ASE14} describes {\em symcretic} execution, a novel combination of symbolic backward execution (SBE) (Section~\ref{se:executors}) and forward symbolic execution. The main idea is to divide exploration into two phases. In the first phase, SBE is performed from a target point and a trace is collected for each followed path. If any problematic constraints are met during the backward exploration, the engine marks them as {\em potentially} satisfiable by adding a special event to the trace and continues its reversed traversal. Whenever an entry point of the program is reached along any of the followed paths, the second phase starts. The engine concretely evaluates the collected trace, trying to satisfy any constraint marked as problematic during the first phase. This is done using a heuristic search, such as the concolic walk described above. An advantage of symcretic over classic concolic execution is that it can prevent the exploration of some unfeasible paths. For instance, the backward phase may determine that a statement is guarded by an unsatisfiable branch regardless of how the statement is reached, while a traditional concolic executor would detect the unfeasibility on a per-path basis only when the statement is reached, which is unfavourable for statements ``deep'' in a path.

%\myparagraph{Memory Page Size}
%In {\sc \stwoe}~\cite{CKC-TOCS12}, when a symbolic pointer is dereferenced, the engine determines which memory pages are referenced by it and passes their contents to the solver. As large page sizes can overwhelm the solver, {\sc \stwoe} uses small pages of configurable size rather than the default 4KB pages. The authors report significant performance benefits from using pages of smaller size.